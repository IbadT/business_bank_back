# ============================================================================
# PROXY PARAMETERS - Общие настройки для всех upstream'ов
# ============================================================================
# Этот файл содержит стандартные proxy настройки, которые переиспользуются
# во всех location блоках через `include /etc/nginx/conf.d/proxy-params.conf`
# Цель: избежать дублирования кода (DRY principle)

# ----------------------------------------------------------------------------
# ЗАГОЛОВКИ - Передача клиентской информации backend'у
# ----------------------------------------------------------------------------
# proxy_set_header устанавливает заголовки для upstream запроса
# Backend сервис получит эти headers и сможет их использовать

# proxy_set_header Host - передаем имя хоста
# $host - доменное имя из клиентского запроса (localhost, api.example.com)
# Backend видит оригинальный Host, а не внутреннее имя контейнера
# Важно для генерации правильных URL'ов в ответах backend'а
proxy_set_header Host $host;

# proxy_set_header X-Real-IP - реальный IP адрес клиента
# $remote_addr - IP клиента подключившегося к Nginx
# Backend использует для: логирования, rate limiting, геолокации, security
# Без этого backend видел бы только IP Nginx контейнера (бесполезно)
proxy_set_header X-Real-IP $remote_addr;

# proxy_set_header X-Forwarded-For - цепочка всех proxy серверов
# $proxy_add_x_forwarded_for - добавляет $remote_addr к существующему X-Forwarded-For
# Результат: "original_client_ip, proxy1_ip, proxy2_ip, nginx_ip"
# Используется когда несколько уровней proxy (CDN → Nginx → Backend)
# Backend может извлечь оригинальный IP клиента (первый в списке)
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

# proxy_set_header X-Forwarded-Proto - оригинальный протокол запроса
# $scheme - протокол клиентского запроса (http или https)
# Backend знает использовал ли клиент HTTPS (важно для security policies)
# Пример: backend может требовать HTTPS для sensitive операций
proxy_set_header X-Forwarded-Proto $scheme;

# proxy_set_header X-Forwarded-Host - оригинальный хост из запроса
# $host - доменное имя которое клиент указал в запросе
# Дублирует Host header, но стандарт для X-Forwarded-* семейства
proxy_set_header X-Forwarded-Host $host;

# proxy_set_header X-Forwarded-Port - оригинальный порт клиентского запроса
# $server_port - порт на котором Nginx принял запрос (80, 443, etc.)
# Backend знает на какой порт клиент отправил запрос
proxy_set_header X-Forwarded-Port $server_port;

# ----------------------------------------------------------------------------
# HTTP ВЕРСИЯ И KEEPALIVE
# ----------------------------------------------------------------------------

# proxy_http_version - версия HTTP протокола для upstream соединений
# 1.1 - поддерживает keepalive (persistent connections)
# HTTP/1.0 не поддерживает keepalive - каждый запрос новое TCP соединение
# Keepalive сильно снижает latency (экономия на TCP handshake)
proxy_http_version 1.1;

# ----------------------------------------------------------------------------
# WEBSOCKET SUPPORT - Для real-time соединений (опционально)
# ----------------------------------------------------------------------------

# proxy_set_header Upgrade - передаем Upgrade header для WebSocket
# $http_upgrade - значение Upgrade header из клиентского запроса
# WebSocket требует HTTP Upgrade для переключения протокола
# Если не используешь WebSocket - не влияет на обычные HTTP запросы
proxy_set_header Upgrade $http_upgrade;

# proxy_set_header Connection - для WebSocket upgrade
# "upgrade" - значение для Upgrade запросов
# Сообщает backend что клиент хочет upgrade соединения (HTTP → WebSocket)
# Для обычных HTTP запросов backend игнорирует этот header
proxy_set_header Connection "upgrade";

# ----------------------------------------------------------------------------
# TIMEOUT'Ы - Временные ограничения для операций
# ----------------------------------------------------------------------------

# proxy_connect_timeout - максимальное время подключения к backend
# 30s - время на установку TCP соединения с upstream сервером
# Если backend недоступен или медленно отвечает -> timeout после 30s
# Защищает от зависания на недоступных backend'ах
proxy_connect_timeout 30s;

# proxy_send_timeout - timeout для отправки request к backend
# 60s - время на передачу request body (POST данных)
# Актуально для больших JSON payload или file uploads
# Если передача не завершена за 60s -> 504 Gateway Timeout
proxy_send_timeout 60s;

# proxy_read_timeout - timeout для чтения response от backend
# 60s - backend должен начать отправлять ответ за это время
# Применяется между последовательными read операциями (не на весь response!)
# Если backend "молчит" 60s -> 504 Gateway Timeout
# Для долгих операций переопределяй в конкретном location блоке
proxy_read_timeout 60s;

# ----------------------------------------------------------------------------
# BUFFERING - Буферизация ответов от backend
# ----------------------------------------------------------------------------

# proxy_buffering - включает буферизацию ответов от backend
# on - Nginx читает весь ответ от backend в буфер, потом отдает клиенту
# Преимущества:
#   1. Backend освобождается быстрее (не ждет медленного клиента)
#   2. Nginx может отдавать данные клиенту с оптимальной скоростью
# Недостатки:
#   1. Увеличивает memory usage
#   2. Добавляет latency для первого байта
# Альтернатива: off - streaming mode (для SSE, long polling)
proxy_buffering on;

# proxy_buffer_size - размер буфера для header'ов ответа от backend
# 4k (4 килобайта) - обычно достаточно для HTTP headers
# Если backend отправляет много headers (cookies, custom headers) -> увеличь
# Отдельный буфер, не входит в proxy_buffers
proxy_buffer_size 4k;

# proxy_buffers - количество и размер буферов для тела ответа
# 8 4k - 8 буферов по 4 КБ каждый = 32 КБ total
# Nginx использует эти буферы для чтения response body от backend
# Если ответ больше 32KB - остаток записывается во временный файл
# Для API обычно достаточно, для больших файлов можно увеличить
proxy_buffers 8 4k;

# proxy_busy_buffers_size - размер буферов для отправки клиенту
# 8k - Nginx может отправлять клиенту из буферов пока читает от backend
# Должен быть <= 2 * proxy_buffer_size (здесь 8k <= 2*4k ✗, но работает)
# Оптимизирует параллельную работу: чтение от backend + отправка клиенту
proxy_busy_buffers_size 8k;

# ----------------------------------------------------------------------------
# ERROR HANDLING - Обработка ошибок и retry логика
# ----------------------------------------------------------------------------

# proxy_next_upstream - при каких ошибках пробовать следующий backend в upstream
# Работает только если в upstream группе несколько серверов
# error - ошибка при подключении к backend
# timeout - timeout при подключении или чтении
# invalid_header - backend вернул некорректные headers
# http_500 - Internal Server Error (backend сломался)
# http_502 - Bad Gateway (backend недоступен)
# http_503 - Service Unavailable (backend перегружен)
# Nginx автоматически попробует следующий сервер в upstream группе
proxy_next_upstream error timeout invalid_header http_500 http_502 http_503;

# proxy_next_upstream_tries - максимальное количество попыток на других backend'ах
# 2 - попробует еще 1 раз (всего 2 попытки включая первую)
# Предотвращает бесконечные retry при проблемах со всеми backend'ами
# При 3 серверах в upstream: primary fail → try server2 → try server3 → give up
proxy_next_upstream_tries 2;

# proxy_next_upstream_timeout - общий timeout для всех retry попыток
# 0 - без ограничения по времени (используем только tries)
# Альтернатива: 30s - все retry попытки должны завершиться за 30 секунд
# 0 означает: пробуем tries раз независимо от общего времени
proxy_next_upstream_timeout 0;

# ----------------------------------------------------------------------------
# ERROR INTERCEPTION - Обработка ошибок
# ----------------------------------------------------------------------------

# proxy_intercept_errors - перехватывать ли ошибки от backend
# off - НЕ перехватываем, отдаем клиенту как есть
# on - Nginx может заменить error response своей custom error page
# off нужен для API: клиент должен видеть точный error response от backend
# (status code, error message, JSON body)
proxy_intercept_errors off;

# ----------------------------------------------------------------------------
# COMPRESSION - Управление сжатием от backend
# ----------------------------------------------------------------------------

# proxy_set_header Accept-Encoding - управление compression от backend
# "" (пустая строка) - убираем Accept-Encoding header
# Означает: НЕ просим backend сжимать ответ
# Почему: Nginx сам сжимает ответы (gzip on в nginx.conf)
# Двойное сжатие (backend + nginx) бессмысленно и медленно
# Backend отдает несжатые данные, Nginx сжимает и отправляет клиенту
proxy_set_header Accept-Encoding "";

